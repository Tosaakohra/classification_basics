{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "\n",
    "df = pd.read_csv(\"processed_data/numerical.csv\", index_col=\"EmployeeID\")\n",
    "X = df[df.columns.difference(['Attrition'])]\n",
    "y = df['Attrition']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 Low variance elimination\n",
    "Delete the features with the low variance. LOW VARIANCE == LESS INFORMATION ... May not be true in some case but ok. \n",
    "\n",
    "Pros:\n",
    "- Easy to implement.\n",
    "- Fast computation. \n",
    "- We don't need a predicted variable so it can be used with the supervised learning.\n",
    "\n",
    "Cons: \n",
    "- Estimating the variance value may be hard. \n",
    "- Hard to measure the effect of the variance to the final results.\n",
    "- Works welll only if the data has the same scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4382, 14)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No feature in X meets the variance threshold 0.90000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-bdfb60c7e0ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mX_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mX_selected\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Documents/Courses/classification_kickstarter/.env/classification/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    688\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    689\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 690\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    691\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    692\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/Courses/classification_kickstarter/.env/classification/lib/python3.7/site-packages/sklearn/feature_selection/_variance_threshold.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" (X contains only one sample)\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No feature in X meets the variance threshold 0.90000"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "variance = VarianceThreshold(threshold=.9)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(X_scaled.shape)\n",
    "X_selected = variance.fit_transform(X_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                        0.047330\n",
       "Attrition_num              0.135032\n",
       "DistanceFromHome           0.083798\n",
       "Education                  0.065629\n",
       "JobLevel                   0.076468\n",
       "MonthlyIncome              0.061627\n",
       "NumCompaniesWorked         0.077027\n",
       "PercentSalaryHike          0.068457\n",
       "StockOptionLevel           0.080731\n",
       "TotalWorkingYears          0.037886\n",
       "TrainingTimesLastYear      0.046182\n",
       "YearsAtCompany             0.023481\n",
       "YearsSinceLastPromotion    0.046225\n",
       "YearsWithCurrManager       0.044092\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_scaled,columns=list(X.columns)).var()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.2 Univariate feature selection\n",
    "Selecting top k features based on the univariate statistical tests.\n",
    "\n",
    "Pros:\n",
    "- Easy to implement.\n",
    "- Fast computation. \n",
    "\n",
    "Cons: \n",
    "- Works with the target variable. \n",
    "- Hard to measure the effect of the variance to the final results.\n",
    "- Works welll only if the data has the same scale.\n",
    "- How to choose the right test ? (need some mathematical knowledge)\n",
    "- How to choose the k ? \n",
    "\n",
    "Lets see example with the chi squared test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4382, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4382, 4)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "feature_selection = SelectKBest(chi2, k=4)\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "print(X_scaled.shape)\n",
    "X_selected = feature_selection.fit_transform(X_scaled, y)\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recursive feature elimination (RFE)\n",
    "This approach uses an external estimator to measure the feature importance:\n",
    "- Starts with all features and looks at the prediction efficiency and the feature importances\n",
    "- Eliminates the feature with lowest importance\n",
    "- Repeats recursively until the result is improving \n",
    "\n",
    "Pros:\n",
    "- Very effective. \n",
    "- Good results. \n",
    "\n",
    "Cons:\n",
    "- Can be very slow (triaining the classifier for each run)\n",
    "- Can be run only for the predictors which provide the feature importances (not that many as we want)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4382, 14)\n",
      "[ True  True False False False False  True False False  True  True False\n",
      "  True  True]\n",
      "[1 1 8 6 5 3 1 4 7 1 1 2 1 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(4382, 7)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "print(X.shape)\n",
    "scaler = MinMaxScaler()\n",
    "feature_selection = RFE(LogisticRegression())\n",
    "\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "feature_selection = feature_selection.fit(X_scaled, y)\n",
    "\n",
    "print(feature_selection.support_)\n",
    "print(feature_selection.ranking_)\n",
    "\n",
    "X_selected = feature_selection.transform(X_scaled)\n",
    "X_selected.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classification",
   "language": "python",
   "name": "classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
